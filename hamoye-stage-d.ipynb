{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:21.912072Z","iopub.execute_input":"2023-01-17T18:21:21.912427Z","iopub.status.idle":"2023-01-17T18:21:22.943766Z","shell.execute_reply.started":"2023-01-17T18:21:21.912396Z","shell.execute_reply":"2023-01-17T18:21:22.942466Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  best_model.hdf5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\n# from google.colab import drive\n# from zipfile import ZipFile","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:22.947412Z","iopub.execute_input":"2023-01-17T18:21:22.948865Z","iopub.status.idle":"2023-01-17T18:21:22.955471Z","shell.execute_reply.started":"2023-01-17T18:21:22.948808Z","shell.execute_reply":"2023-01-17T18:21:22.954392Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Path to needed csv files\ntraining_csv = '/kaggle/input/planets-dataset/planet/planet/train_classes.csv'\ntesting_csv = '/kaggle/input/planets-dataset/planet/planet/sample_submission.csv'","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:22.957145Z","iopub.execute_input":"2023-01-17T18:21:22.957683Z","iopub.status.idle":"2023-01-17T18:21:22.975194Z","shell.execute_reply.started":"2023-01-17T18:21:22.957642Z","shell.execute_reply":"2023-01-17T18:21:22.974192Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# # Unzipping the large jpg files\n# with ZipFile('/content/drive/MyDrive/Planet/train-jpg.zip', 'r') as zipObj:\n#   zipObj.extractall('sample_data/new_train')\n\n# with ZipFile('/content/drive/MyDrive/Planet/test-jpg.zip', 'r') as zipObj:\n#   zipObj.extractall('sample_data/new_test')\n\n# with ZipFile('/content/drive/MyDrive/Planet/test-jpg-additional.zip', 'r') as zipObj:\n#   zipObj.extractall('sample_data/new_add_test')","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:22.976863Z","iopub.execute_input":"2023-01-17T18:21:22.977420Z","iopub.status.idle":"2023-01-17T18:21:22.986854Z","shell.execute_reply.started":"2023-01-17T18:21:22.977385Z","shell.execute_reply":"2023-01-17T18:21:22.985717Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Reading in the training data\ntraining_class = pd.read_csv(training_csv)\ntraining_class.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:22.990849Z","iopub.execute_input":"2023-01-17T18:21:22.991237Z","iopub.status.idle":"2023-01-17T18:21:23.031157Z","shell.execute_reply.started":"2023-01-17T18:21:22.991202Z","shell.execute_reply":"2023-01-17T18:21:23.029981Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Creating a function to split and store unique tags\nlabels = set()\ndef splitting_tags(tags):\n    for tag in tags.split():\n        labels.add(tag)\n\n# Creating a copy of the training class dataset to work on\ntraining_class_dummy = training_class.copy()\ntraining_class_dummy['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.032509Z","iopub.execute_input":"2023-01-17T18:21:23.032817Z","iopub.status.idle":"2023-01-17T18:21:23.075591Z","shell.execute_reply.started":"2023-01-17T18:21:23.032785Z","shell.execute_reply":"2023-01-17T18:21:23.074618Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"['primary', 'road', 'conventional_mine', 'clear', 'partly_cloudy', 'cultivation', 'agriculture', 'water', 'blooming', 'habitation', 'bare_ground', 'slash_burn', 'selective_logging', 'artisinal_mine', 'cloudy', 'blow_down', 'haze']\n","output_type":"stream"}]},{"cell_type":"code","source":"#Confirming  that the length of the df is the same as the shape\nassert len(training_class_dummy['image_name'].unique()) == training_class_dummy.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.076914Z","iopub.execute_input":"2023-01-17T18:21:23.077318Z","iopub.status.idle":"2023-01-17T18:21:23.088184Z","shell.execute_reply.started":"2023-01-17T18:21:23.077284Z","shell.execute_reply":"2023-01-17T18:21:23.087098Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes\nfor tag in labels:\n    training_class_dummy[tag] = training_class_dummy['tags'].apply(lambda x: 1 if tag in x.split() else 0)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.089557Z","iopub.execute_input":"2023-01-17T18:21:23.090008Z","iopub.status.idle":"2023-01-17T18:21:23.483381Z","shell.execute_reply.started":"2023-01-17T18:21:23.089973Z","shell.execute_reply":"2023-01-17T18:21:23.482446Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes\nfor tag in labels:\n    training_class_dummy[tag] = training_class_dummy['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n## adding .jpg extension to the column image_name so as to have same name format as the image files\ntraining_class_dummy['image_name'] = training_class_dummy['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntraining_class_dummy.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.486629Z","iopub.execute_input":"2023-01-17T18:21:23.486921Z","iopub.status.idle":"2023-01-17T18:21:23.911677Z","shell.execute_reply.started":"2023-01-17T18:21:23.486893Z","shell.execute_reply":"2023-01-17T18:21:23.910761Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"    image_name                                       tags  primary  road  \\\n0  train_0.jpg                               haze primary        1     0   \n1  train_1.jpg            agriculture clear primary water        1     0   \n2  train_2.jpg                              clear primary        1     0   \n3  train_3.jpg                              clear primary        1     0   \n4  train_4.jpg  agriculture clear habitation primary road        1     1   \n\n   conventional_mine  clear  partly_cloudy  cultivation  agriculture  water  \\\n0                  0      0              0            0            0      0   \n1                  0      1              0            0            1      1   \n2                  0      1              0            0            0      0   \n3                  0      1              0            0            0      0   \n4                  0      1              0            0            1      0   \n\n   blooming  habitation  bare_ground  slash_burn  selective_logging  \\\n0         0           0            0           0                  0   \n1         0           0            0           0                  0   \n2         0           0            0           0                  0   \n3         0           0            0           0                  0   \n4         0           1            0           0                  0   \n\n   artisinal_mine  cloudy  blow_down  haze  \n0               0       0          0     1  \n1               0       0          0     0  \n2               0       0          0     0  \n3               0       0          0     0  \n4               0       0          0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n      <th>primary</th>\n      <th>road</th>\n      <th>conventional_mine</th>\n      <th>clear</th>\n      <th>partly_cloudy</th>\n      <th>cultivation</th>\n      <th>agriculture</th>\n      <th>water</th>\n      <th>blooming</th>\n      <th>habitation</th>\n      <th>bare_ground</th>\n      <th>slash_burn</th>\n      <th>selective_logging</th>\n      <th>artisinal_mine</th>\n      <th>cloudy</th>\n      <th>blow_down</th>\n      <th>haze</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0.jpg</td>\n      <td>haze primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1.jpg</td>\n      <td>agriculture clear primary water</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4.jpg</td>\n      <td>agriculture clear habitation primary road</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#importing necessary libraries for training\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.913003Z","iopub.execute_input":"2023-01-17T18:21:23.913381Z","iopub.status.idle":"2023-01-17T18:21:23.919955Z","shell.execute_reply.started":"2023-01-17T18:21:23.913344Z","shell.execute_reply":"2023-01-17T18:21:23.918977Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Checking out our newly created features via one hot encoding. Actually started from index 2\ncolumns = list(training_class_dummy.columns[2:]) \ncolumns","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.921350Z","iopub.execute_input":"2023-01-17T18:21:23.922327Z","iopub.status.idle":"2023-01-17T18:21:23.933256Z","shell.execute_reply.started":"2023-01-17T18:21:23.922291Z","shell.execute_reply":"2023-01-17T18:21:23.932355Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"['primary',\n 'road',\n 'conventional_mine',\n 'clear',\n 'partly_cloudy',\n 'cultivation',\n 'agriculture',\n 'water',\n 'blooming',\n 'habitation',\n 'bare_ground',\n 'slash_burn',\n 'selective_logging',\n 'artisinal_mine',\n 'cloudy',\n 'blow_down',\n 'haze']"},"metadata":{}}]},{"cell_type":"code","source":"#define a function for fbeta scoring\ndef fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n    \n    beta_squared = beta**2\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n    return fb","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.936422Z","iopub.execute_input":"2023-01-17T18:21:23.936715Z","iopub.status.idle":"2023-01-17T18:21:23.948763Z","shell.execute_reply.started":"2023-01-17T18:21:23.936690Z","shell.execute_reply":"2023-01-17T18:21:23.946493Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#define a function for accuracy for multi_label classification\ndef multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n        \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n                       axis = 1)\n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.951641Z","iopub.execute_input":"2023-01-17T18:21:23.952192Z","iopub.status.idle":"2023-01-17T18:21:23.974629Z","shell.execute_reply.started":"2023-01-17T18:21:23.952128Z","shell.execute_reply":"2023-01-17T18:21:23.973879Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#defining our model using a function build_model()\ndef build_model():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n\n    opt = Adam(learning_rate=1e-4)\n\n    model.compile(loss='binary_crossentropy',\n              # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n              optimizer=opt,\n              metrics=[multi_label_acc, fbeta])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:23.988728Z","iopub.execute_input":"2023-01-17T18:21:23.989347Z","iopub.status.idle":"2023-01-17T18:21:24.018371Z","shell.execute_reply.started":"2023-01-17T18:21:23.989307Z","shell.execute_reply":"2023-01-17T18:21:24.017117Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\nsave_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', monitor = 'val_fbeta', mode = 'max',\n                                       save_best_only = True, save_weights_only = True)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:24.023938Z","iopub.execute_input":"2023-01-17T18:21:24.024358Z","iopub.status.idle":"2023-01-17T18:21:24.032158Z","shell.execute_reply.started":"2023-01-17T18:21:24.024316Z","shell.execute_reply":"2023-01-17T18:21:24.031176Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#initializing imagedatagenerator with a validation split of 0.2\ntrain_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n\n#generating train data generator which is 80% of the train dataset\n#note that a generator contains both features and target of the data\ntrain_generator = train_image_gen.flow_from_dataframe(dataframe=training_class_dummy,\n                                                directory =\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))\n\n#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\nval_generator = train_image_gen.flow_from_dataframe(dataframe=training_class_dummy,\n                                                directory =\"/kaggle/input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:24.033825Z","iopub.execute_input":"2023-01-17T18:21:24.034537Z","iopub.status.idle":"2023-01-17T18:21:42.356985Z","shell.execute_reply.started":"2023-01-17T18:21:24.034501Z","shell.execute_reply":"2023-01-17T18:21:42.355965Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Found 32384 validated image filenames.\nFound 8095 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#setting up step size for training and validation image data\nstep_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\nstep_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:42.358360Z","iopub.execute_input":"2023-01-17T18:21:42.359011Z","iopub.status.idle":"2023-01-17T18:21:42.366254Z","shell.execute_reply.started":"2023-01-17T18:21:42.358970Z","shell.execute_reply":"2023-01-17T18:21:42.364852Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#initializing the model\nmodel1 = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:42.368568Z","iopub.execute_input":"2023-01-17T18:21:42.369175Z","iopub.status.idle":"2023-01-17T18:21:42.495361Z","shell.execute_reply.started":"2023-01-17T18:21:42.369076Z","shell.execute_reply":"2023-01-17T18:21:42.494446Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#this shows the summary of the model, simply put as the model architecture\nmodel1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:42.496588Z","iopub.execute_input":"2023-01-17T18:21:42.496949Z","iopub.status.idle":"2023-01-17T18:21:42.507164Z","shell.execute_reply.started":"2023-01-17T18:21:42.496914Z","shell.execute_reply":"2023-01-17T18:21:42.503372Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization_1 (Batch (None, 128, 128, 3)       12        \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 128, 128, 32)      896       \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 126, 126, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 63, 63, 32)        0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 63, 63, 32)        0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 63, 63, 64)        18496     \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 61, 61, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 30, 30, 64)        0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 30, 30, 128)       73856     \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 28, 28, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 14, 14, 256)       295168    \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 12, 12, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 9216)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               4719104   \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 17)                8721      \n=================================================================\nTotal params: 5,900,093\nTrainable params: 5,900,087\nNon-trainable params: 6\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#fitting our model using the parameters already defined \nmodel1.fit(x = train_generator, steps_per_epoch = step_train_size, validation_data = val_generator, \n           validation_steps = step_val_size,epochs = 10, \n           callbacks = [save_best_check_point])","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:21:42.508367Z","iopub.execute_input":"2023-01-17T18:21:42.509280Z","iopub.status.idle":"2023-01-17T18:43:20.278047Z","shell.execute_reply.started":"2023-01-17T18:21:42.509244Z","shell.execute_reply":"2023-01-17T18:43:20.276909Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/10\n2024/2024 [==============================] - 121s 59ms/step - loss: 0.2199 - multi_label_acc: 0.9163 - fbeta: 0.6960 - val_loss: 0.1634 - val_multi_label_acc: 0.9355 - val_fbeta: 0.7764\nEpoch 2/10\n2024/2024 [==============================] - 128s 63ms/step - loss: 0.1456 - multi_label_acc: 0.9423 - fbeta: 0.8126 - val_loss: 0.1326 - val_multi_label_acc: 0.9474 - val_fbeta: 0.8319\nEpoch 4/10\n2024/2024 [==============================] - 136s 67ms/step - loss: 0.1364 - multi_label_acc: 0.9457 - fbeta: 0.8272 - val_loss: 0.1283 - val_multi_label_acc: 0.9503 - val_fbeta: 0.8452\nEpoch 5/10\n2024/2024 [==============================] - 130s 64ms/step - loss: 0.1242 - multi_label_acc: 0.9509 - fbeta: 0.8471 - val_loss: 0.1194 - val_multi_label_acc: 0.9528 - val_fbeta: 0.8484\nEpoch 7/10\n2024/2024 [==============================] - 127s 63ms/step - loss: 0.1195 - multi_label_acc: 0.9527 - fbeta: 0.8542 - val_loss: 0.1145 - val_multi_label_acc: 0.9559 - val_fbeta: 0.8626\nEpoch 8/10\n2024/2024 [==============================] - 126s 62ms/step - loss: 0.1154 - multi_label_acc: 0.9546 - fbeta: 0.8610 - val_loss: 0.1132 - val_multi_label_acc: 0.9559 - val_fbeta: 0.8664\nEpoch 9/10\n2024/2024 [==============================] - 136s 67ms/step - loss: 0.1126 - multi_label_acc: 0.9558 - fbeta: 0.8653 - val_loss: 0.1101 - val_multi_label_acc: 0.9573 - val_fbeta: 0.8702\nEpoch 10/10\n2024/2024 [==============================] - 136s 67ms/step - loss: 0.1085 - multi_label_acc: 0.9575 - fbeta: 0.8716 - val_loss: 0.1073 - val_multi_label_acc: 0.9587 - val_fbeta: 0.8765\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f4c2b791110>"},"metadata":{}}]},{"cell_type":"code","source":"#initializing a second model so we can make predictions\nmodel2 = build_model()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:43:20.280035Z","iopub.execute_input":"2023-01-17T18:43:20.280459Z","iopub.status.idle":"2023-01-17T18:43:20.416911Z","shell.execute_reply.started":"2023-01-17T18:43:20.280417Z","shell.execute_reply":"2023-01-17T18:43:20.415872Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#adding .jpg extension to image name in the sample submission file\nsample_submission = pd.read_csv('/kaggle/input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:43:20.418467Z","iopub.execute_input":"2023-01-17T18:43:20.419135Z","iopub.status.idle":"2023-01-17T18:43:20.537673Z","shell.execute_reply.started":"2023-01-17T18:43:20.419097Z","shell.execute_reply":"2023-01-17T18:43:20.536630Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   image_name                                  tags\n0  test_0.jpg  primary clear agriculture road water\n1  test_1.jpg  primary clear agriculture road water\n2  test_2.jpg  primary clear agriculture road water\n3  test_3.jpg  primary clear agriculture road water\n4  test_4.jpg  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#loading in the weights of the trained model so we can make predictions with it\nmodel2.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:43:20.539060Z","iopub.execute_input":"2023-01-17T18:43:20.539974Z","iopub.status.idle":"2023-01-17T18:43:20.609803Z","shell.execute_reply.started":"2023-01-17T18:43:20.539934Z","shell.execute_reply":"2023-01-17T18:43:20.608762Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# we divide the sample submission file into two splits, first test1_df which contains the first 40669 images \ntest1_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\ntest1_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:43:20.611282Z","iopub.execute_input":"2023-01-17T18:43:20.611654Z","iopub.status.idle":"2023-01-17T18:43:20.627783Z","shell.execute_reply.started":"2023-01-17T18:43:20.611617Z","shell.execute_reply":"2023-01-17T18:43:20.626877Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"   image_name\n0  test_0.jpg\n1  test_1.jpg\n2  test_2.jpg\n3  test_3.jpg\n4  test_4.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#initializing imagedatagenerator for the test images and also rescaling\ntest_image_gen = ImageDataGenerator(rescale = 1/255)\n\n\n#creating a generator for the images found in the first test image files\ntest_generator1 = test_image_gen.flow_from_dataframe(dataframe=test1_df, \n                                                directory=\"/kaggle/input/planets-dataset/planet/planet/test-jpg\", \n                                                x_col=\"image_name\", y_col=None, batch_size=16, \n                                                shuffle=False, class_mode=None, target_size=(128,128))\n\nstep_test_size1 = int(np.ceil(test_generator1.samples/test_generator1.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:43:20.629440Z","iopub.execute_input":"2023-01-17T18:43:20.629851Z","iopub.status.idle":"2023-01-17T18:44:32.646844Z","shell.execute_reply.started":"2023-01-17T18:43:20.629798Z","shell.execute_reply":"2023-01-17T18:44:32.645096Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Found 40669 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#first, we reset the test generator to avoid shuffling of index as we want it to be orderly\ntest_generator1.reset()\npred1 = model2.predict(test_generator1, steps = step_test_size1, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:44:32.648952Z","iopub.execute_input":"2023-01-17T18:44:32.650336Z","iopub.status.idle":"2023-01-17T18:48:27.829354Z","shell.execute_reply.started":"2023-01-17T18:44:32.650287Z","shell.execute_reply":"2023-01-17T18:48:27.828443Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"2542/2542 [==============================] - 235s 92ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names1 = test_generator1.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5 \npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this \nresult1 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\nresult1.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:48:27.830995Z","iopub.execute_input":"2023-01-17T18:48:27.831324Z","iopub.status.idle":"2023-01-17T18:48:36.084387Z","shell.execute_reply.started":"2023-01-17T18:48:27.831295Z","shell.execute_reply":"2023-01-17T18:48:36.083377Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          primary clear\n1  test_1.jpg          primary clear\n2  test_2.jpg  primary partly_cloudy\n3  test_3.jpg          primary clear\n4  test_4.jpg  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#second batch of the test dataset\ntest2_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\ntest2_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:48:36.086029Z","iopub.execute_input":"2023-01-17T18:48:36.086665Z","iopub.status.idle":"2023-01-17T18:48:36.099739Z","shell.execute_reply.started":"2023-01-17T18:48:36.086626Z","shell.execute_reply":"2023-01-17T18:48:36.098686Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"      image_name\n0     file_0.jpg\n1     file_1.jpg\n2    file_10.jpg\n3   file_100.jpg\n4  file_1000.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#creating a generator for the second batch of test image files\ntest_generator2 = test_image_gen.flow_from_dataframe(dataframe=test2_df, \n                                                directory=\"/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n                                                x_col=\"image_name\", y_col=None, batch_size=16, \n                                                shuffle=False, class_mode=None, target_size=(128,128))\n\nstep_test_size2 = int(np.ceil(test_generator2.samples/test_generator2.batch_size))","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:48:36.102920Z","iopub.execute_input":"2023-01-17T18:48:36.103209Z","iopub.status.idle":"2023-01-17T18:49:12.963952Z","shell.execute_reply.started":"2023-01-17T18:48:36.103175Z","shell.execute_reply":"2023-01-17T18:49:12.962647Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Found 20522 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"#we reset the generator to avoid shuffling, then make prediction on the generator\ntest_generator2.reset()\npred2 = model2.predict(test_generator2, steps = step_test_size2, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:49:12.965701Z","iopub.execute_input":"2023-01-17T18:49:12.966826Z","iopub.status.idle":"2023-01-17T18:51:15.209251Z","shell.execute_reply.started":"2023-01-17T18:49:12.966776Z","shell.execute_reply":"2023-01-17T18:51:15.208021Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"1283/1283 [==============================] - 122s 95ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names2 = test_generator2.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5\npred_tags2 = pd.DataFrame(pred2)\npred_tags2 = pred_tags2.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this\nresult2 = pd.DataFrame({'image_name': file_names2, 'tags': pred_tags2})\nresult2.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:51:15.211472Z","iopub.execute_input":"2023-01-17T18:51:15.212429Z","iopub.status.idle":"2023-01-17T18:51:20.117944Z","shell.execute_reply.started":"2023-01-17T18:51:15.212378Z","shell.execute_reply":"2023-01-17T18:51:20.116790Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"      image_name                             tags\n0     file_0.jpg                     primaryclear\n1     file_1.jpg  primarypartly_cloudyagriculture\n2    file_10.jpg           primaryroadagriculture\n3   file_100.jpg                primaryclearwater\n4  file_1000.jpg                     primaryclear","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n      <td>primaryclear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n      <td>primarypartly_cloudyagriculture</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n      <td>primaryroadagriculture</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n      <td>primaryclearwater</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n      <td>primaryclear</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#for the final result of the predicted tags for the test images, we need to concat the first and second results in \n#that order to avoid shuffling the index\nlast_result = pd.concat([result1, result2])\n\nlast_result = last_result.reset_index().drop('index', axis =1)\n\nprint(last_result.shape)\n#print the final result\nlast_result.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:51:20.119441Z","iopub.execute_input":"2023-01-17T18:51:20.120586Z","iopub.status.idle":"2023-01-17T18:51:20.143286Z","shell.execute_reply.started":"2023-01-17T18:51:20.120543Z","shell.execute_reply":"2023-01-17T18:51:20.142021Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"(61191, 2)\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"   image_name                   tags\n0  test_0.jpg          primary clear\n1  test_1.jpg          primary clear\n2  test_2.jpg  primary partly_cloudy\n3  test_3.jpg          primary clear\n4  test_4.jpg  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Removing the .jpg extension from the image_name of the last_result which was added for ease of manipulation of the data.\nlast_result['image_name'] = last_result['image_name'].apply(lambda x: x[:-4])\nlast_result.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:51:20.144965Z","iopub.execute_input":"2023-01-17T18:51:20.145623Z","iopub.status.idle":"2023-01-17T18:51:20.179903Z","shell.execute_reply.started":"2023-01-17T18:51:20.145577Z","shell.execute_reply":"2023-01-17T18:51:20.178890Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"  image_name                   tags\n0     test_0          primary clear\n1     test_1          primary clear\n2     test_2  primary partly_cloudy\n3     test_3          primary clear\n4     test_4  primary partly_cloudy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>primary clear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>primary partly_cloudy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# #Finally, we save the result to a csv file using the .to_csv() method and setting the index to false.\nlast_result.to_csv('submission13.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T18:51:20.181313Z","iopub.execute_input":"2023-01-17T18:51:20.181794Z","iopub.status.idle":"2023-01-17T18:51:20.271974Z","shell.execute_reply.started":"2023-01-17T18:51:20.181755Z","shell.execute_reply":"2023-01-17T18:51:20.270893Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}